{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d4c6497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import send2trash\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG,format='%(asctime)s - %(levelname)s - %(message)s', filename='logs.log', filemode='w' )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def rm_file(filename):\n",
    "    path = os.path.expanduser(os.path.join(filename))\n",
    "    if os.path.exists(path):\n",
    "        logger.info(f\"Removing existing file: {path}\")\n",
    "        try:\n",
    "            # Rename the file to a temporary name\n",
    "            temp_path = os.path.splitext(path)[0] + \"_temp\" + os.path.splitext(path)[1]\n",
    "            os.rename(path, temp_path)\n",
    "\n",
    "            # Delete the renamed file\n",
    "            send2trash.send2trash(temp_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error removing file {path}: {e}\")\n",
    "    else:\n",
    "        logger.warning(f\"{path} does not exist\")\n",
    "# check if data is available\n",
    "def get_available_data_years():\n",
    "    current_year = datetime.now().year\n",
    "    year = current_year\n",
    "    available_years = []\n",
    "    while year >= current_year - 4:  \n",
    "        response = requests.get(f\"https://api.census.gov/data/{year}/acs/acs5?get=B01001_001E,B19013_001E&for=state:*&key={api_key}\")\n",
    "        if response.status_code == 200:\n",
    "            available_years.append(year)  \n",
    "        year -= 1  \n",
    "    return available_years  \n",
    "\n",
    "# Function to create sub-batches\n",
    "def create_sub_batches(group, max_batch_size):\n",
    "    for start in range(0, len(group), max_batch_size):\n",
    "        end = start + max_batch_size\n",
    "        yield group.iloc[start:end]\n",
    "\n",
    "def estimate_income(input_csv, output_csv, percentage_increase):\n",
    "    # Load the existing data\n",
    "    data_df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Determine the latest year in the data\n",
    "    latest_year = data_df['year'].max()\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    # Create a DataFrame to store the estimated data\n",
    "    estimated_df = pd.DataFrame()\n",
    "\n",
    "    # Estimate income for each year from the latest year in the data to the current year\n",
    "    for year in range(latest_year + 1, current_year + 1):\n",
    "        temp_df = data_df[data_df['year'] == latest_year].copy()\n",
    "        temp_df['MedianIncome'] *= (1 + percentage_increase) ** (year - latest_year)\n",
    "        temp_df['year'] = year\n",
    "        temp_df['_last_synced_'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        estimated_df = pd.concat([estimated_df, temp_df])\n",
    "    # Append the estimated data to the output CSV file\n",
    "    header = not (os.path.exists(output_csv) and os.path.getsize(output_csv) > 0)\n",
    "    estimated_df[['MedianIncome', 'RegionName', 'year', 'state_fip',\n",
    "       '_last_synced_']].to_csv(output_csv, mode='a', header=header, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7dc861f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pop_income_data(years, zip_grouped):\n",
    "    for year in years:\n",
    "        # Process each group\n",
    "        for state_fips, group in zip_grouped:\n",
    "            # Create sub-batches for each group\n",
    "            for sub_batch in create_sub_batches(group, max_batch_size):\n",
    "                fib = sub_batch['statefips'].iloc[0]\n",
    "                logger.debug(f\"queryinig data for year: {year}, State Fib: {sub_batch['statefips'].iloc[0]}/{total_states}\")\n",
    "                # Check if the file exists and is not empty for each batch\n",
    "                header = not (os.path.exists(output_pop_income) and os.path.getsize(output_pop_income) > 0)\n",
    "\n",
    "                # Join all zip codes in the sub-batch into a single string\n",
    "                zip_codes = ','.join(sub_batch['RegionName'].astype(str))\n",
    "\n",
    "                url = f\"https://api.census.gov/data/{year}/acs/acs5?get=B01001_001E,B19013_001E&for=zip%20code%20tabulation%20area:{zip_codes}&key={api_key}\"\n",
    "\n",
    "                # Make the API request\n",
    "                response = requests.get(url)\n",
    "\n",
    "\n",
    "                # Check if the request was successful\n",
    "                if response.status_code == 200:\n",
    "                    logger.info(f\"data reterived for: {year}, State Fib: {fib}/{total_states}\")\n",
    "\n",
    "                    data = response.json()\n",
    "                    df = pd.DataFrame(data[1:])\n",
    "                    df.columns = ['Population', 'MedianIncome', 'RegionName']\n",
    "                    df['year'] = year\n",
    "                    df['state_fip'] = fib\n",
    "                    df['_last_synced_'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    # Append to the CSV file\n",
    "                    df.to_csv(output_pop_income, mode='a', header=header, index=False)\n",
    "                    logger.info(f\"Data for state {fib}, batch appended to CSV\")\n",
    "                else:\n",
    "                    if \"ambiguous geography\" in response.text:\n",
    "                        url = f\"https://api.census.gov/data/{year}/acs/acs5?get=B01001_001E,B19013_001E&for=state:{fib}&for=zip%20code%20tabulation%20area:{zip_codes}&key={api_key}\"\n",
    "                        # Make the API request\n",
    "                        response = requests.get(url)\n",
    "                        if response.status_code == 200:\n",
    "                            data = response.json()\n",
    "                            df = pd.DataFrame(data[1:])\n",
    "                            df.columns = ['Population', 'MedianIncome', 'RegionName']\n",
    "                            df['year'] = year\n",
    "                            df['state_fip'] = fib\n",
    "                            df['_last_synced_'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            # Append to the CSV file\n",
    "                            df.to_csv(output_pop_income, mode='a', header=header, index=False)\n",
    "                            logger.info(f\"Data for state {fib}, batch appended to CSV\")\n",
    "                    logger.error(f\"Failed to retrieve data for state {fib}, Status code: {response.status_code}, Response: {response.text}\") \n",
    "                    \n",
    "                \n",
    "def main():\n",
    "    logger.info(\"Starting process ...\")\n",
    "    rm_file(output_pop_income)\n",
    "    rm_file(output_income_estimate)\n",
    "    years = get_available_data_years()\n",
    "    logger.info(f\"fetching data for year: {years}\")\n",
    "    zips_df = pd.read_csv('regions.csv')[['RegionID', 'RegionName', 'statefips']]\n",
    "    zip_grouped = zips_df.groupby('statefips')\n",
    "    get_pop_income_data(years, zip_grouped)\n",
    "    estimate_income(output_pop_income, output_income_estimate, percentage_increase)\n",
    "    logger.info(\"Process compeleted\")\n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81e4e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_path = './census_data'\n",
    "output_pop_income = f'{data_output_path}/population_income.csv'\n",
    "output_income_estimate = f'{data_output_path}/income_estimate.csv'\n",
    "percentage_increase = 0.03  # 3% annual increase\n",
    "api_key = \"a1af1e42e9841a9683efcc2d7c0f6f41dfd84755\"\n",
    "# api_key = \"3fbd6a8fda31d606916c9cc0807b8cc8a07bac1e\"\n",
    "\n",
    "# Maximum number of zip codes per batch\n",
    "max_batch_size = 500\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9512a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
